{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e368f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fakerNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001DF00B73770>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/faker/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001DF00D24550>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/faker/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001DF00D247D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/faker/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001DF00D24A50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/faker/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001DF00D24CD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/faker/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading faker-37.6.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tzdata in c:\\users\\nrna1\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from faker) (2025.2)\n",
      "Downloading faker-37.6.0-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 1.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/1.9 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/1.9 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/1.9 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/1.9 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: faker\n",
      "Successfully installed faker-37.6.0\n"
     ]
    }
   ],
   "source": [
    "pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf27c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd8b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# -------------------\n",
    "# CONFIG\n",
    "# -------------------\n",
    "N_CUSTOMERS = 100_000\n",
    "N_WAREHOUSES = 50\n",
    "N_ORDERS = 1_000_000\n",
    "N_ORDER_ITEMS = 2_000_000\n",
    "N_PAYMENTS = N_ORDERS\n",
    "N_CAMPAIGNS = 5000\n",
    "\n",
    "# -------------------\n",
    "# CUSTOMERS\n",
    "# -------------------\n",
    "customers = []\n",
    "for i in range(N_CUSTOMERS):\n",
    "    customers.append([\n",
    "        i+1,\n",
    "        fake.name(),\n",
    "        fake.email(),\n",
    "        fake.date_between(start_date='-2y', end_date='today'),\n",
    "        fake.city(),\n",
    "        random.choice([\"Yes\", \"No\"])  # Prime user\n",
    "    ])\n",
    "customers_df = pd.DataFrame(customers, columns=[\"customer_id\",\"name\",\"email\",\"signup_date\",\"location\",\"is_prime_user\"])\n",
    "\n",
    "# Add dirtiness: missing emails, duplicate customers\n",
    "customers_df.loc[customers_df.sample(frac=0.05).index, \"email\"] = None\n",
    "customers_df = pd.concat([customers_df, customers_df.sample(frac=0.01)])  # 1% duplicates\n",
    "\n",
    "# -------------------\n",
    "# WAREHOUSES\n",
    "# -------------------\n",
    "warehouses = []\n",
    "for i in range(N_WAREHOUSES):\n",
    "    warehouses.append([\n",
    "        i+1,\n",
    "        fake.city(),\n",
    "        round(random.uniform(0.5, 1.2), 2)  # capacity utilization\n",
    "    ])\n",
    "warehouses_df = pd.DataFrame(warehouses, columns=[\"warehouse_id\",\"location\",\"capacity_utilization\"])\n",
    "\n",
    "# -------------------\n",
    "# ORDERS\n",
    "# -------------------\n",
    "orders = []\n",
    "for i in range(N_ORDERS):\n",
    "    orders.append([\n",
    "        i+1,\n",
    "        random.randint(1, N_CUSTOMERS+200),  # some invalid customer_ids\n",
    "        fake.date_time_between(start_date='-1y', end_date='now'),\n",
    "        random.randint(1, N_WAREHOUSES+10),  # some invalid warehouse_ids\n",
    "        random.choice([\"delivered\",\"cancelled\",\"returned\"]),\n",
    "        round(random.uniform(50, 1500), 2),\n",
    "        random.choice([10, 12, 15, 20, 25, 500])  # delivery time, with outliers\n",
    "    ])\n",
    "orders_df = pd.DataFrame(orders, columns=[\"order_id\",\"customer_id\",\"order_date\",\"warehouse_id\",\"status\",\"total_value\",\"delivery_time_minutes\"])\n",
    "\n",
    "# Dirtiness: missing delivery times, mixed date formats\n",
    "orders_df.loc[orders_df.sample(frac=0.05).index, \"delivery_time_minutes\"] = None\n",
    "orders_df.loc[orders_df.sample(frac=0.01).index, \"order_date\"] = orders_df[\"order_date\"].astype(str)\n",
    "\n",
    "# -------------------\n",
    "# ORDER ITEMS\n",
    "# -------------------\n",
    "order_items = []\n",
    "for i in range(N_ORDER_ITEMS):\n",
    "    order_items.append([\n",
    "        i+1,\n",
    "        random.randint(1, N_ORDERS),\n",
    "        random.randint(1, 2000),  # product_id\n",
    "        random.randint(1, 5),\n",
    "        round(random.uniform(5.0, 500.0), 2)\n",
    "    ])\n",
    "order_items_df = pd.DataFrame(order_items, columns=[\"order_item_id\",\"order_id\",\"product_id\",\"quantity\",\"price_per_unit\"])\n",
    "\n",
    "# -------------------\n",
    "# PAYMENTS\n",
    "# -------------------\n",
    "payment_methods = [\"UPI\", \"upi\", \"gpay\", \"PhonePe\", \"Credit Card\", \"COD\", \"Wallet\"]\n",
    "payments = []\n",
    "for i in range(N_PAYMENTS):\n",
    "    payments.append([\n",
    "        i+1,\n",
    "        random.randint(1, N_ORDERS),\n",
    "        fake.date_time_between(start_date='-1y', end_date='now'),\n",
    "        random.choice(payment_methods),\n",
    "        round(random.uniform(50.0, 1500.0), 2)\n",
    "    ])\n",
    "payments_df = pd.DataFrame(payments, columns=[\"payment_id\",\"order_id\",\"payment_date\",\"method\",\"amount\"])\n",
    "\n",
    "# Dirtiness: missing methods\n",
    "payments_df.loc[payments_df.sample(frac=0.02).index, \"method\"] = None\n",
    "\n",
    "# -------------------\n",
    "# CAMPAIGNS\n",
    "# -------------------\n",
    "channels = [\"App Notification\", \"Email\", \"SMS\", \"Push\"]\n",
    "campaigns = []\n",
    "for i in range(N_CAMPAIGNS):\n",
    "    impressions = random.randint(1000, 100000)\n",
    "    clicks = random.randint(0, impressions)\n",
    "    conversions = random.randint(0, clicks)\n",
    "    spend = round(random.uniform(100, 10000), 2)\n",
    "    campaigns.append([\n",
    "        i+1,\n",
    "        random.choice(channels),\n",
    "        impressions,\n",
    "        clicks,\n",
    "        conversions,\n",
    "        spend\n",
    "    ])\n",
    "campaigns_df = pd.DataFrame(campaigns, columns=[\"campaign_id\",\"channel\",\"impressions\",\"clicks\",\"conversions\",\"spend\"])\n",
    "\n",
    "# -------------------\n",
    "# SAVE TO CSV\n",
    "# -------------------\n",
    "customers_df.to_csv(\"blinkit_customers.csv\", index=False)\n",
    "warehouses_df.to_csv(\"blinkit_warehouses.csv\", index=False)\n",
    "orders_df.to_csv(\"blinkit_orders.csv\", index=False)\n",
    "order_items_df.to_csv(\"blinkit_order_items.csv\", index=False)\n",
    "payments_df.to_csv(\"blinkit_payments.csv\", index=False)\n",
    "campaigns_df.to_csv(\"blinkit_campaigns.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
